import { View, Text, SafeAreaView, TouchableOpacity, Alert } from 'react-native';
import { NativeStackScreenProps } from '@react-navigation/native-stack';
import { RootStackParamList } from '../App';
import HiddenCamera from '../components/HiddenCamera';
import TempMicTest from '../components/TempMicTest';
import AnswerMic from '../components/AnswerMic';
import NextButton from '../components/NextButton';
import EndChatButton from '../components/EndChatButton';
import { useState, useEffect } from 'react';
import ttsService from '../services/audio/ttsService';
import sttService from '../services/audio/sttService';
import conversationApiService from '../services/api/conversationApiService';
import microphoneApiService from '../services/api/microphoneApiService';

type Props = NativeStackScreenProps<RootStackParamList, 'UserAnswer'>;

export default function UserAnswer({ route, navigation }: Props) {
    const { 
        questionText, 
        questionId, 
        conversationId, 
        cameraSessionId, 
        microphoneSessionId 
    } = route.params || { questionText: 'ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.' };
    const [isMicTested, setIsMicTested] = useState(false);
    const [hasAnswerRecording, setHasAnswerRecording] = useState(false);
    const [isPlaying, setIsPlaying] = useState(false);
    const [volume, setVolume] = useState(1.0);
    const [isRecording, setIsRecording] = useState(false);
    const [transcribedText, setTranscribedText] = useState<string | null>(null);

    const handleNext = () => {
        // AIê°€ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ í•˜ëŠ” í™”ë©´ìœ¼ë¡œ ì´ë™
        navigation.navigate('AIChat', { 
            questionText: 'ìƒˆë¡œìš´ ì§ˆë¬¸ì…ë‹ˆë‹¤.',
            questionId,
            conversationId,
            cameraSessionId,
            microphoneSessionId
        });
    };

    const handleEndChat = async () => {
        // ë°œí™” ì¢…ë£Œ API í˜¸ì¶œ
        if (microphoneSessionId && cameraSessionId) {
            try {
                const userId = 'user-123'; // ì‹¤ì œë¡œëŠ” ë¡œê·¸ì¸ëœ ì‚¬ìš©ì ID ì‚¬ìš©
                const speechEndResult = await microphoneApiService.endSpeech(
                    microphoneSessionId,
                    cameraSessionId,
                    userId
                );
                console.log('ë°œí™” ì¢…ë£Œë¨:', speechEndResult);
            } catch (error) {
                console.error('ë°œí™” ì¢…ë£Œ ì‹¤íŒ¨:', error);
            }
        }
        
        // ë§ˆì´í¬ ì„¸ì…˜ ì¢…ë£Œ
        if (microphoneSessionId) {
            try {
                await microphoneApiService.endSession(microphoneSessionId);
                console.log('ë§ˆì´í¬ ì„¸ì…˜ ì¢…ë£Œë¨:', microphoneSessionId);
            } catch (error) {
                console.error('ë§ˆì´í¬ ì„¸ì…˜ ì¢…ë£Œ ì‹¤íŒ¨:', error);
            }
        }
        
        // ëŒ€í™” ì„¸ì…˜ ì¢…ë£Œ
        if (conversationId) {
            try {
                await conversationApiService.endConversation(conversationId);
                console.log('ëŒ€í™” ì„¸ì…˜ ì¢…ë£Œë¨:', conversationId);
            } catch (error) {
                console.error('ëŒ€í™” ì„¸ì…˜ ì¢…ë£Œ ì‹¤íŒ¨:', error);
            }
        }
        
        // ì±„íŒ… í™”ë©´ìœ¼ë¡œ ì´ë™í•˜ë©´ì„œ ëŒ€í™” ë‚´ìš© ì „ë‹¬
        navigation.navigate('Chat', { 
            chatHistory: [
                {
                    id: 1,
                    type: 'ai',
                    message: questionText,
                    timestamp: new Date().toLocaleTimeString('ko-KR', { 
                        hour: '2-digit', 
                        minute: '2-digit' 
                    })
                },
                {
                    id: 2,
                    type: 'user',
                    message: transcribedText || 'ì‚¬ìš©ìì˜ ë‹µë³€ ë‚´ìš©ì…ë‹ˆë‹¤.',
                    timestamp: new Date().toLocaleTimeString('ko-KR', { 
                        hour: '2-digit', 
                        minute: '2-digit' 
                    })
                }
            ]
        });
    };

    const handleMicTest = () => {
        setIsMicTested(true);
    };

    const handleAnswerRecordingComplete = async (audioUri: string, questionId: string) => {
        console.log(`ë‹µë³€ ë…¹ìŒ ì™„ë£Œ - ì§ˆë¬¸ ID: ${questionId}, ì˜¤ë””ì˜¤ URI: ${audioUri}`);
        
        try {
            // ë§ˆì´í¬ ì„¸ì…˜ ìƒíƒœë¥¼ RECORDINGìœ¼ë¡œ ì—…ë°ì´íŠ¸
            if (microphoneSessionId) {
                await microphoneApiService.updateSessionStatus(microphoneSessionId, 'RECORDING');
                console.log('ë§ˆì´í¬ ì„¸ì…˜ ìƒíƒœê°€ RECORDINGìœ¼ë¡œ ì—…ë°ì´íŠ¸ë¨');
            }
            
            // AnswerMicì—ì„œ ë…¹ìŒí•œ ì˜¤ë””ì˜¤ë¥¼ STTë¡œ ë³€í™˜
            const sttResult = await sttService.transcribeAudioFromUri(audioUri);
            if (sttResult && sttResult.text) {
                setTranscribedText(sttResult.text);
                console.log('STT ë³€í™˜ ê²°ê³¼:', sttResult.text);
                
                // ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ì €ì¥
                if (conversationId && sttResult.text) {
                    try {
                        await conversationApiService.saveUserMessage(conversationId, sttResult.text);
                        console.log('ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ì €ì¥ë¨:', sttResult.text);
                    } catch (error) {
                        console.error('ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨:', error);
                    }
                }
            } else {
                console.log('STT ë³€í™˜ ì‹¤íŒ¨');
            }
        } catch (error) {
            console.error('STT ë³€í™˜ ì¤‘ ì˜¤ë¥˜:', error);
        }
        
        setHasAnswerRecording(true);
    };

    const handleAnswerRecordingStart = async (questionId: string) => {
        console.log(`ë‹µë³€ ë…¹ìŒ ì‹œì‘ - ì§ˆë¬¸ ID: ${questionId}`);
        setIsRecording(true);
    };

    // TTSë¡œ ì§ˆë¬¸ ì½ê¸°
    const handlePlayQuestion = async () => {
        if (isPlaying) {
            await ttsService.stopAudio();
            setIsPlaying(false);
            return;
        }

        try {
            setIsPlaying(true);
            const ttsResult = await ttsService.synthesizeText(questionText);
            
            if (ttsResult && ttsResult.audioData) {
                await ttsService.playAudio(ttsResult.audioData, ttsResult.format, volume);
            } else {
                console.error('TTS ë³€í™˜ ì‹¤íŒ¨');
                setIsPlaying(false);
            }
        } catch (error) {
            console.error('ì§ˆë¬¸ ì¬ìƒ ì‹¤íŒ¨:', error);
            setIsPlaying(false);
        }
    };

    // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ STT ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    useEffect(() => {
        const checkSTTHealth = async () => {
            try {
                const isHealthy = await sttService.checkHealth();
                console.log('STT ì„œë¹„ìŠ¤ ìƒíƒœ:', isHealthy ? 'ì •ìƒ' : 'ì˜¤ë¥˜');
            } catch (error) {
                console.error('STT ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
            }
        };
        
        checkSTTHealth();
        
        return () => {
            ttsService.destroy();
            sttService.cleanup();
        };
    }, []);

    return (
        <SafeAreaView className="flex-1 bg-white">
            {/* ë©”ì¸ ì»¨í…ì¸  */}
            <View className="flex-1 p-6">
                {/* ìˆ¨ê²¨ì§„ ì¹´ë©”ë¼ (ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ì „ì†¡) */}
                <HiddenCamera 
                    onFaceDetected={(imageData) => {
                        // AI ì„œë²„ë¡œ ì´ë¯¸ì§€ ë°ì´í„°ë§Œ ì „ì†¡ (AIê°€ ê°ì • ë¶„ì„)
                        //console.log('ì´ë¯¸ì§€ ë°ì´í„° AI ì„œë²„ ì „ì†¡:', imageData);
                    }}
                />

                {/* ìºë¦­í„°ì™€ ì§ˆë¬¸ */}
                <View className="flex-1 justify-center items-center mb-8">
                    {/* ìºë¦­í„° */}
                    <TouchableOpacity 
                        onPress={handlePlayQuestion}
                        className="w-32 h-32 bg-blue-100 rounded-full justify-center items-center mb-6"
                        activeOpacity={0.7}
                    >
                        <Text className="text-4xl">ğŸ¤–</Text>
                        {/* ì¬ìƒ/ì •ì§€ í‘œì‹œ */}
                        <View className="absolute bottom-2 right-2">
                            <Text className="text-lg">
                                {isPlaying ? 'â¹ï¸' : 'â–¶ï¸'}
                            </Text>
                        </View>
                    </TouchableOpacity>
                    
                    {/* ë§í’ì„  */}
                    <View className="bg-gray-100 rounded-2xl p-4 mx-4 mb-8 relative">
                        {/* ë§í’ì„  ê¼¬ë¦¬ */}
                        <View className="absolute -top-2 left-1/2 transform -translate-x-1/2">
                            <View className="w-4 h-4 bg-gray-100 rotate-45"></View>
                        </View>
                        <Text className="text-lg text-center text-gray-800 leading-6">
                            {questionText}
                        </Text>
                    </View>
                </View>

                {/* ë‹µë³€ ë…¹ìŒ */}
                <View className="items-center mb-8">
                    <AnswerMic 
                        questionId={questionId || `question-${Date.now()}`}
                        microphoneSessionId={microphoneSessionId}
                        onRecordingComplete={handleAnswerRecordingComplete}
                        onRecordingStart={handleAnswerRecordingStart}
                        maxDuration={10} // 10ì´ˆë¡œ ë‹¨ì¶•
                    />
                    
                    {/* ë…¹ìŒ ìƒíƒœ í‘œì‹œ */}
                    {isRecording && (
                        <View className="mt-4 bg-red-100 px-4 py-2 rounded-full">
                            <Text className="text-red-600 font-medium">ğŸ¤ ë…¹ìŒ ì¤‘...</Text>
                        </View>
                    )}
                    
                    {/* STT ë³€í™˜ ê²°ê³¼ í‘œì‹œ (ë””ë²„ê¹…ìš©) */}
                    {transcribedText && (
                        <View className="mt-4 bg-green-100 p-3 rounded-lg max-w-sm">
                            <Text className="text-green-800 text-sm">
                                ë³€í™˜ëœ í…ìŠ¤íŠ¸: {transcribedText}
                            </Text>
                        </View>
                    )}
                </View>

                {/* ë²„íŠ¼ë“¤ */}
                <View className="w-full">
                    <View className="mb-2">
                        <NextButton onPress={handleNext} />
                    </View>
                    <EndChatButton onPress={handleEndChat} />
                </View>
            </View>
        </SafeAreaView>
    );
} 