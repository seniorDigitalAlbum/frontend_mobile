import React, { useState, useRef, useEffect } from 'react';
import { View, Text, TouchableOpacity, Animated, Alert, Platform } from 'react-native';
import { Ionicons } from '@expo/vector-icons';
import { Audio } from 'expo-av';
import microphoneApiService from '../services/api/microphoneApiService';

interface AnswerMicProps {
    questionId: string;
    microphoneSessionId?: string;
    cameraSessionId?: string;
    conversationId?: string;
    userId?: string;
    onRecordingComplete?: (audioUri: string, questionId: string) => void;
    onRecordingStart?: (questionId: string) => void;
    onAIResponse?: (aiResponse: string, audioBase64?: string, conversationMessageId?: number) => void;
    maxDuration?: number; // ìµœëŒ€ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
}

export default function AnswerMic({ 
    questionId,
    microphoneSessionId,
    cameraSessionId,
    conversationId,
    userId,
    onRecordingComplete, 
    onRecordingStart,
    onAIResponse,
    maxDuration = 120 
}: AnswerMicProps) {
    const [isRecording, setIsRecording] = useState(false);
    const [recordingDuration, setRecordingDuration] = useState(0);
    const [audioLevel, setAudioLevel] = useState(0);
    const recordingRef = useRef<Audio.Recording | null>(null);
    const durationRef = useRef<NodeJS.Timeout | null>(null);
    const audioLevelAnimation = useRef(new Animated.Value(0)).current;

    useEffect(() => {
        return () => {
            if (recordingRef.current) {
                recordingRef.current.stopAndUnloadAsync();
            }
            if (durationRef.current) {
                clearInterval(durationRef.current);
            }
        };
    }, []);

    // ì˜¤ë””ì˜¤ íŒŒì¼ì„ Base64ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    const convertAudioToBase64 = async (uri: string): Promise<string> => {
        try {
            const response = await fetch(uri);
            const blob = await response.blob();
            
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    const base64 = reader.result as string;
                    // data:audio/wav;base64, ë¶€ë¶„ì„ ì œê±°í•˜ê³  ìˆœìˆ˜ Base64ë§Œ ë°˜í™˜
                    const base64Data = base64.split(',')[1];
                    resolve(base64Data);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        } catch (error) {
            console.error('ì˜¤ë””ì˜¤ Base64 ë³€í™˜ ì‹¤íŒ¨:', error);
            throw error;
        }
    };

    const startRecording = async () => {
        try {
            // ì˜¤ë””ì˜¤ ê¶Œí•œ ìš”ì²­
            const { status } = await Audio.requestPermissionsAsync();
            if (status !== 'granted') {
                Alert.alert('ê¶Œí•œ í•„ìš”', 'ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
                return;
            }

            // ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì •
            await Audio.setAudioModeAsync({
                allowsRecordingIOS: true,
                playsInSilentModeIOS: true,
            });

            // í”Œë«í¼ë³„ ë…¹ìŒ ì„¤ì •
            let recordingOptions;
            
            if (Platform.OS === 'web') {
                // ì›¹ í™˜ê²½: WebM í˜•ì‹ ì‚¬ìš© (ëª¨ë“  í”Œë«í¼ ì„¤ì • í¬í•¨)
                recordingOptions = {
                    web: {
                        mimeType: 'audio/webm;codecs=opus',
                        bitsPerSecond: 128000,
                    },
                    android: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_DEFAULT,
                        audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_DEFAULT,
                        sampleRate: 8000,
                        numberOfChannels: 1,
                        bitRate: 32000,
                    },
                    ios: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_IOS_OUTPUT_FORMAT_LINEARPCM,
                        audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_LOW,
                        sampleRate: 8000,
                        numberOfChannels: 1,
                        bitRate: 32000,
                        linearPCMBitDepth: 16,
                        linearPCMIsBigEndian: false,
                        linearPCMIsFloat: false,
                    },
                };
            } else {
                // ëª¨ë°”ì¼ í™˜ê²½: ì••ì¶•ëœ WAV í˜•ì‹ ì‚¬ìš©
                recordingOptions = {
                    android: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_DEFAULT,
                        audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_DEFAULT,
                        sampleRate: 8000, // ë‚®ì€ ìƒ˜í”Œë ˆì´íŠ¸
                        numberOfChannels: 1,
                        bitRate: 32000, // ë‚®ì€ ë¹„íŠ¸ë ˆì´íŠ¸
                    },
                    ios: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_IOS_OUTPUT_FORMAT_LINEARPCM,
                        audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_LOW,
                        sampleRate: 8000, // ë‚®ì€ ìƒ˜í”Œë ˆì´íŠ¸
                        numberOfChannels: 1,
                        bitRate: 32000, // ë‚®ì€ ë¹„íŠ¸ë ˆì´íŠ¸
                        linearPCMBitDepth: 16,
                        linearPCMIsBigEndian: false,
                        linearPCMIsFloat: false,
                    },
                };
            }

            const { recording } = await Audio.Recording.createAsync(recordingOptions);
            
            recordingRef.current = recording;
            setIsRecording(true);
            setRecordingDuration(0);
            
            console.log('ğŸ¤ ë…¹ìŒ ì‹œì‘ë¨ - duration timer ì‹œì‘');

            // ë°œí™” ì‹œì‘ API í˜¸ì¶œ
            if (microphoneSessionId && cameraSessionId) {
                try {
                    const speechStartResponse = await microphoneApiService.startSpeech({
                        userId: "1",
                        microphoneSessionId: microphoneSessionId,
                        cameraSessionId: cameraSessionId
                    });
                    console.log('ë°œí™” ì‹œì‘ë¨:', speechStartResponse);
                } catch (error) {
                    console.error('ë°œí™” ì‹œì‘ ì‹¤íŒ¨:', error);
                }
            }
            
            // ë…¹ìŒ ì‹œì‘ ì½œë°±
            if (onRecordingStart) {
                onRecordingStart(questionId);
            }

            // ë…¹ìŒ ì‹œê°„ ì¹´ìš´í„°
            durationRef.current = setInterval(() => {
                setRecordingDuration(prev => {
                    const newDuration = prev + 1;
                    console.log(`â±ï¸ ë…¹ìŒ ì‹œê°„: ${newDuration}ì´ˆ / ${maxDuration}ì´ˆ`);
                    // ìµœëŒ€ ì‹œê°„ ë„ë‹¬ ì‹œ ìë™ ì¤‘ì§€
                    if (newDuration >= maxDuration) {
                        console.log('â±ï¸ ìµœëŒ€ ì‹œê°„ ë„ë‹¬ - ìë™ ì¤‘ì§€');
                        stopRecording();
                        return maxDuration;
                    }
                    return newDuration;
                });
            }, 1000);

            // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ (ì‹œë®¬ë ˆì´ì…˜)
            const audioInterval = setInterval(() => {
                if (isRecording) {
                    const level = Math.random() * 0.8 + 0.2;
                    setAudioLevel(level);
                    
                    Animated.timing(audioLevelAnimation, {
                        toValue: level,
                        duration: 100,
                        useNativeDriver: false,
                    }).start();
                }
            }, 100);

            // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
            return () => clearInterval(audioInterval);

        } catch (error) {
            console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
            setIsRecording(false);
        }
    };

    const stopRecording = async () => {
        console.log('ğŸ›‘ stopRecording í˜¸ì¶œë¨');
        if (!recordingRef.current) {
            console.log('ğŸ›‘ recordingRefê°€ null - ë…¹ìŒì´ ì´ë¯¸ ì¢…ë£Œë¨');
            return;
        }

        try {
            console.log('ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ ì¤‘...');
            await recordingRef.current.stopAndUnloadAsync();
            const uri = recordingRef.current.getURI();
            console.log('ğŸ›‘ ë…¹ìŒ íŒŒì¼ URI:', uri);
            
            setIsRecording(false);
            setAudioLevel(0);
            audioLevelAnimation.setValue(0);
            
            if (durationRef.current) {
                clearInterval(durationRef.current);
                durationRef.current = null;
                console.log('ğŸ›‘ duration timer ì •ë¦¬ë¨');
            }

            // ë°œí™” ì¢…ë£Œ API í˜¸ì¶œ
            if (microphoneSessionId && cameraSessionId && uri) {
                try {
                    // ì˜¤ë””ì˜¤ íŒŒì¼ì„ Base64ë¡œ ë³€í™˜
                    const audioBase64 = await convertAudioToBase64(uri);
                    
                    const speechEndResponse = await microphoneApiService.endSpeech({
                        microphoneSessionId: microphoneSessionId,
                        cameraSessionId: cameraSessionId,
                        userId: "1",
                        conversationId: conversationId,
                        audioData: audioBase64 // Base64ë¡œ ë³€í™˜ëœ ì˜¤ë””ì˜¤ ë°ì´í„°
                    });
                    console.log('ë°œí™” ì¢…ë£Œë¨:', speechEndResponse);
                    
                    // AI ì‘ë‹µì„ ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ë¡œ ì „ë‹¬
                    if (speechEndResponse && speechEndResponse.status === 'success' && onAIResponse) {
                        onAIResponse(speechEndResponse.userText, '', speechEndResponse.conversationMessageId);
                    }
                } catch (error) {
                    console.error('ë°œí™” ì¢…ë£Œ ì‹¤íŒ¨:', error);
                }
            }

            // ë…¹ìŒ ì™„ë£Œ ì½œë°±
            if (uri && onRecordingComplete) {
                onRecordingComplete(uri, questionId);
            }

            recordingRef.current = null;

        } catch (error) {
            console.error('ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨:', error);
        }
    };

    const formatTime = (seconds: number) => {
        const mins = Math.floor(seconds / 60);
        const secs = seconds % 60;
        return `${mins}:${secs.toString().padStart(2, '0')}`;
    };

    const handlePress = () => {
        if (isRecording) {
            stopRecording();
        } else {
            startRecording();
        }
    };

    return (
        <View className="items-center">
            <TouchableOpacity 
                onPress={handlePress}
                className={`w-20 h-20 rounded-full justify-center items-center ${
                    isRecording ? 'bg-red-100' : 'bg-blue-100'
                }`}
                activeOpacity={0.7}
            >
                <Ionicons 
                    name={isRecording ? "stop" : "mic"} 
                    size={32} 
                    color={isRecording ? "#EF4444" : "#3B82F6"} 
                />
                
                {/* ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ í‘œì‹œ */}
                {isRecording && (
                    <View className="absolute -bottom-6 left-0 right-0 items-center">
                        <View className="flex-row items-end space-x-1 h-6">
                            {[...Array(4)].map((_, index) => (
                                <Animated.View
                                    key={index}
                                    className="w-1 bg-red-500 rounded-full"
                                    style={{
                                        height: audioLevelAnimation.interpolate({
                                            inputRange: [0, 1],
                                            outputRange: [2, 16],
                                        }),
                                        opacity: audioLevelAnimation.interpolate({
                                            inputRange: [0, 1],
                                            outputRange: [0.3, 1],
                                        }),
                                    }}
                                />
                            ))}
                        </View>
                    </View>
                )}
            </TouchableOpacity>
            
            {/* ë…¹ìŒ ìƒíƒœ í…ìŠ¤íŠ¸ */}
            {/* <Text className={`text-sm font-medium mt-2 ${
                isRecording ? 'text-red-700' : 'text-blue-700'
            }`}>
                {isRecording ? `ë…¹ìŒ ì¤‘ ${formatTime(recordingDuration)}` : 'ë‹µë³€ ë…¹ìŒ'}
            </Text> */}

            {/* ìµœëŒ€ ì‹œê°„ í‘œì‹œ */}
            {/* {isRecording && (
                <Text className="text-xs text-gray-500 mt-1">
                    ìµœëŒ€ {formatTime(maxDuration)}
                </Text>
            )} */}
        </View>
    );
}
