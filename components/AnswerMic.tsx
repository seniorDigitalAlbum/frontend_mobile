import React, { useState, useRef, useEffect } from 'react';
import { View, Text, TouchableOpacity, Animated, Alert, Platform, ActivityIndicator } from 'react-native';
import { Ionicons } from '@expo/vector-icons';
import { Audio } from 'expo-av';
import microphoneApiService from '../services/api/microphoneApiService';
import { colors } from '../styles/commonStyles';

interface AnswerMicProps {
    questionId: string;
    microphoneSessionId?: string;
    cameraSessionId?: string;
    conversationId?: string;
    userId?: string;
    onRecordingComplete?: (audioUri: string, questionId: string) => void;
    onRecordingStart?: (questionId: string) => void;
    onAIResponse?: (aiResponse: string, audioBase64?: string, conversationMessageId?: number) => void;
    maxDuration?: number; // ìµœëŒ€ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
}

export default function AnswerMic({ 
    questionId,
    microphoneSessionId,
    cameraSessionId,
    conversationId,
    userId,
    onRecordingComplete, 
    onRecordingStart,
    onAIResponse,
    maxDuration = 120 
}: AnswerMicProps) {
    const [isRecording, setIsRecording] = useState(false);
    const [isStartingRecording, setIsStartingRecording] = useState(false);
    const [recordingDuration, setRecordingDuration] = useState(0);
    const [audioLevel, setAudioLevel] = useState(0);
    const recordingRef = useRef<Audio.Recording | null>(null);
    const durationRef = useRef<NodeJS.Timeout | null>(null);
    const audioLevelAnimation = useRef(new Animated.Value(0)).current;

    useEffect(() => {
        // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ê¸°ì¡´ ë…¹ìŒ ê°ì²´ ì •ë¦¬
        const cleanupExistingRecording = async () => {
            try {
                // ê¸°ì¡´ ë…¹ìŒì´ ìˆë‹¤ë©´ ì •ë¦¬
                if (recordingRef.current) {
                    console.log('ê¸°ì¡´ ë…¹ìŒ ê°ì²´ ì •ë¦¬ ì¤‘...');
                    await recordingRef.current.stopAndUnloadAsync();
                    recordingRef.current = null;
                }
                
                // ê¸°ì¡´ íƒ€ì´ë¨¸ ì •ë¦¬
                if (durationRef.current) {
                    clearInterval(durationRef.current);
                    durationRef.current = null;
                }
                
                // ìƒíƒœ ì´ˆê¸°í™”
                setIsRecording(false);
                setIsStartingRecording(false);
                setRecordingDuration(0);
                setAudioLevel(0);
            } catch (error) {
                console.log('ê¸°ì¡´ ë…¹ìŒ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨):', error);
            }
        };
        
        cleanupExistingRecording();
        
        return () => {
            if (recordingRef.current) {
                recordingRef.current.stopAndUnloadAsync();
            }
            if (durationRef.current) {
                clearInterval(durationRef.current);
            }
        };
    }, []);

    // ì˜¤ë””ì˜¤ íŒŒì¼ì„ Base64ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    const convertAudioToBase64 = async (uri: string): Promise<string> => {
        try {
            const response = await fetch(uri);
            const blob = await response.blob();
            
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    const base64 = reader.result as string;
                    // data:audio/wav;base64, ë¶€ë¶„ì„ ì œê±°í•˜ê³  ìˆœìˆ˜ Base64ë§Œ ë°˜í™˜
                    const base64Data = base64.split(',')[1];
                    resolve(base64Data);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        } catch (error) {
            console.error('ì˜¤ë””ì˜¤ Base64 ë³€í™˜ ì‹¤íŒ¨:', error);
            throw error;
        }
    };

    const startRecording = async () => {
        try {
            // ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ê±°ë‚˜ ì‹œì‘ ì¤‘ì´ë©´ ì¤‘ë³µ ì‹œì‘ ë°©ì§€
            if (isRecording || isStartingRecording || recordingRef.current) {
                console.log('ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ê±°ë‚˜ ì‹œì‘ ì¤‘ì…ë‹ˆë‹¤. ì¤‘ë³µ ì‹œì‘ì„ ë°©ì§€í•©ë‹ˆë‹¤.');
                return;
            }

            // ë…¹ìŒ ì‹œì‘ ë¡œë”© ìƒíƒœ ì„¤ì •
            setIsStartingRecording(true);

            // ì˜¤ë””ì˜¤ ê¶Œí•œ ìš”ì²­
            const { status } = await Audio.requestPermissionsAsync();
            if (status !== 'granted') {
                Alert.alert('ê¶Œí•œ í•„ìš”', 'ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
                setIsStartingRecording(false);
                return;
            }

            // ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì •
            await Audio.setAudioModeAsync({
                allowsRecordingIOS: true,
                playsInSilentModeIOS: true,
            });

            // í”Œë«í¼ë³„ ë…¹ìŒ ì„¤ì •
            let recordingOptions;
            
            if (Platform.OS === 'web') {
                // ì›¹ í™˜ê²½: WebM í˜•ì‹ ì‚¬ìš© (ëª¨ë“  í”Œë«í¼ ì„¤ì • í¬í•¨)
                recordingOptions = {
                    web: {
                        mimeType: 'audio/webm;codecs=opus',
                        bitsPerSecond: 128000,
                    },
                    android: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_DEFAULT,
                        audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_DEFAULT,
                        sampleRate: 8000,
                        numberOfChannels: 1,
                        bitRate: 32000,
                    },
                    ios: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_IOS_OUTPUT_FORMAT_LINEARPCM,
                        audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_LOW,
                        sampleRate: 8000,
                        numberOfChannels: 1,
                        bitRate: 32000,
                        linearPCMBitDepth: 16,
                        linearPCMIsBigEndian: false,
                        linearPCMIsFloat: false,
                    },
                };
            } else {
                // ëª¨ë°”ì¼ í™˜ê²½: ì••ì¶•ëœ WAV í˜•ì‹ ì‚¬ìš©
                recordingOptions = {
                    android: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_DEFAULT,
                        audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_DEFAULT,
                        sampleRate: 8000, // ë‚®ì€ ìƒ˜í”Œë ˆì´íŠ¸
                        numberOfChannels: 1,
                        bitRate: 32000, // ë‚®ì€ ë¹„íŠ¸ë ˆì´íŠ¸
                    },
                    ios: {
                        extension: '.wav',
                        outputFormat: Audio.RECORDING_OPTION_IOS_OUTPUT_FORMAT_LINEARPCM,
                        audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_LOW,
                        sampleRate: 8000, // ë‚®ì€ ìƒ˜í”Œë ˆì´íŠ¸
                        numberOfChannels: 1,
                        bitRate: 32000, // ë‚®ì€ ë¹„íŠ¸ë ˆì´íŠ¸
                        linearPCMBitDepth: 16,
                        linearPCMIsBigEndian: false,
                        linearPCMIsFloat: false,
                    },
                };
            }

            const { recording } = await Audio.Recording.createAsync(recordingOptions);
            
            recordingRef.current = recording;
            setIsRecording(true);
            setIsStartingRecording(false); // ë¡œë”© ìƒíƒœ í•´ì œ
            setRecordingDuration(0);
            
            console.log('ğŸ¤ ë…¹ìŒ ì‹œì‘ë¨ - duration timer ì‹œì‘');

            // ë°œí™” ì‹œì‘ API í˜¸ì¶œ
            if (microphoneSessionId && cameraSessionId) {
                try {
                    const speechStartResponse = await microphoneApiService.startSpeech({
                        userId: userId || "1",
                        microphoneSessionId: microphoneSessionId,
                        cameraSessionId: cameraSessionId
                    });
                    console.log('ë°œí™” ì‹œì‘ë¨:', speechStartResponse);
                } catch (error) {
                    console.error('ë°œí™” ì‹œì‘ ì‹¤íŒ¨:', error);
                    
                    // RECORDING ìƒíƒœ ì˜¤ë¥˜ì¸ ê²½ìš° ì„¸ì…˜ ì •ë¦¬ í›„ ì¬ì‹œë„
                    if (error instanceof Error && error.message.includes('í˜„ì¬ ìƒíƒœ: RECORDING')) {
                        console.log('ë§ˆì´í¬ ì„¸ì…˜ì´ RECORDING ìƒíƒœì…ë‹ˆë‹¤. ì„¸ì…˜ì„ ì •ë¦¬í•˜ê³  ì¬ì‹œë„í•©ë‹ˆë‹¤.');
                        try {
                            // ê¸°ì¡´ ë°œí™” ì¢…ë£Œ ì‹œë„
                            await microphoneApiService.endSpeech({
                                microphoneSessionId: microphoneSessionId,
                                cameraSessionId: cameraSessionId,
                                userId: userId || "1",
                                conversationId: conversationId,
                                audioData: "" // ë¹ˆ ë°ì´í„°ë¡œ ê°•ì œ ì¢…ë£Œ
                            });
                            
                            // ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                            await new Promise(resolve => setTimeout(resolve, 1000));
                            
                            const retryResponse = await microphoneApiService.startSpeech({
                                userId: userId || "1",
                                microphoneSessionId: microphoneSessionId,
                                cameraSessionId: cameraSessionId
                            });
                            console.log('ì¬ì‹œë„ í›„ ë°œí™” ì‹œì‘ë¨:', retryResponse);
                        } catch (retryError) {
                            console.error('ì¬ì‹œë„ í›„ì—ë„ ë°œí™” ì‹œì‘ ì‹¤íŒ¨:', retryError);
                        }
                    }
                }
            }
            
            // ë…¹ìŒ ì‹œì‘ ì½œë°±
            if (onRecordingStart) {
                onRecordingStart(questionId);
            }

            // ë…¹ìŒ ì‹œê°„ ì¹´ìš´í„°
            durationRef.current = setInterval(() => {
                setRecordingDuration(prev => {
                    const newDuration = prev + 1;
                    console.log(`â±ï¸ ë…¹ìŒ ì‹œê°„: ${newDuration}ì´ˆ / ${maxDuration}ì´ˆ`);
                    // ìµœëŒ€ ì‹œê°„ ë„ë‹¬ ì‹œ ìë™ ì¤‘ì§€
                    if (newDuration >= maxDuration) {
                        console.log('â±ï¸ ìµœëŒ€ ì‹œê°„ ë„ë‹¬ - ìë™ ì¤‘ì§€');
                        stopRecording();
                        return maxDuration;
                    }
                    return newDuration;
                });
            }, 1000);

            // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ (ì‹œë®¬ë ˆì´ì…˜)
            const audioInterval = setInterval(() => {
                if (isRecording) {
                    const level = Math.random() * 0.8 + 0.2;
                    setAudioLevel(level);
                    
                    Animated.timing(audioLevelAnimation, {
                        toValue: level,
                        duration: 100,
                        useNativeDriver: false,
                    }).start();
                }
            }, 100);

            // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
            return () => clearInterval(audioInterval);

        } catch (error) {
            console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
            setIsRecording(false);
            setIsStartingRecording(false); // ì—ëŸ¬ ì‹œì—ë„ ë¡œë”© ìƒíƒœ í•´ì œ
        }
    };

    const stopRecording = async () => {
        console.log('ğŸ›‘ stopRecording í˜¸ì¶œë¨');
        if (!recordingRef.current) {
            console.log('ğŸ›‘ recordingRefê°€ null - ë…¹ìŒì´ ì´ë¯¸ ì¢…ë£Œë¨');
            return;
        }

        try {
            console.log('ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ ì¤‘...');
            await recordingRef.current.stopAndUnloadAsync();
            const uri = recordingRef.current.getURI();
            console.log('ğŸ›‘ ë…¹ìŒ íŒŒì¼ URI:', uri);
            
            setIsRecording(false);
            setAudioLevel(0);
            audioLevelAnimation.setValue(0);
            
            // ì¦‰ì‹œ ì²˜ë¦¬ ìƒíƒœ ì‹œì‘ - "ë‹¤ìŒë§ì„ ìƒì„±í•˜ê³  ìˆì–´ìš”..." í‘œì‹œ
            if (onAIResponse) {
                onAIResponse('', '', 0); // ë¹ˆ ê°’ìœ¼ë¡œ ì¦‰ì‹œ ì²˜ë¦¬ ìƒíƒœ ì‹œì‘
            }
            
            if (durationRef.current) {
                clearInterval(durationRef.current);
                durationRef.current = null;
            }

            // ë°œí™” ì¢…ë£Œ API í˜¸ì¶œ
            if (microphoneSessionId && cameraSessionId && uri) {
                try {
                    // ì˜¤ë””ì˜¤ íŒŒì¼ì„ Base64ë¡œ ë³€í™˜
                    const audioBase64 = await convertAudioToBase64(uri);
                    
                    // ë…¹ìŒ ì‹œê°„ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬
                    if (recordingDuration < 1) {
                        // ì§§ì€ ë…¹ìŒì— ëŒ€í•œ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
                    }
                    
                    const speechEndResponse = await microphoneApiService.endSpeech({
                        microphoneSessionId: microphoneSessionId,
                        cameraSessionId: cameraSessionId,
                        userId: userId || "1",
                        conversationId: conversationId,
                        audioData: audioBase64 // Base64ë¡œ ë³€í™˜ëœ ì˜¤ë””ì˜¤ ë°ì´í„°
                    });
                    
                    // AI ì‘ë‹µì„ ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ë¡œ ì „ë‹¬ (ì‹¤ì œ ì²˜ë¦¬)
                    if (speechEndResponse && speechEndResponse.status === 'success' && onAIResponse) {
                        onAIResponse(speechEndResponse.userText, '', speechEndResponse.conversationMessageId);
                    }
                } catch (error) {
                    console.error('ë°œí™” ì¢…ë£Œ ì‹¤íŒ¨:', error);
                }
            }

            // ë…¹ìŒ ì™„ë£Œ ì½œë°±
            if (uri && onRecordingComplete) {
                onRecordingComplete(uri, questionId);
            }

            recordingRef.current = null;

        } catch (error) {
            console.error('ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨:', error);
        }
    };

    const formatTime = (seconds: number) => {
        const mins = Math.floor(seconds / 60);
        const secs = seconds % 60;
        return `${mins}:${secs.toString().padStart(2, '0')}`;
    };

    const handlePress = () => {
        if (isRecording) {
            stopRecording();
        } else if (!isStartingRecording) {
            startRecording();
        }
    };

    return (
        <View className="items-center">
            {/* ë…¹ìŒ ìƒíƒœ í‘œì‹œ - ë§ˆì´í¬ ìœ„ì— */}
            {isRecording && (
                <View className="mb-4 px-4 py-2 rounded-full" style={{ backgroundColor: '#E8F5E8' }}>
                    <Text className="font-medium text-2xl" style={{ color: colors.green }}>ë“£ê³  ìˆì–´ìš”.</Text>
                </View>
            )}
            
            {/* ë§ˆì´í¬ ë²„íŠ¼ */}
            <View className="w-40 h-40 justify-center items-center mb-4">
                <TouchableOpacity 
                    onPress={handlePress}
                    className={`w-36 h-36 rounded-full justify-center items-center ${
                        isRecording ? '' : 'bg-green-100'
                    }`}
                    style={isRecording ? { backgroundColor: colors.green } : undefined}
                    activeOpacity={0.7}
                    disabled={isStartingRecording}
                >
                    {isStartingRecording ? (
                        <ActivityIndicator size="large" color={colors.green} />
                    ) : (
                        <Ionicons 
                            name={isRecording ? "stop" : "mic"} 
                            size={64} 
                            color={isRecording ? "#FFFFFF" : colors.green} 
                        />
                    )}
                </TouchableOpacity>
                
                {/* ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ í‘œì‹œ */}
                {/* {isRecording && (
                    <View className="absolute -bottom-12 left-0 right-0 items-center">
                        <View className="flex-row items-end space-x-2 h-12">
                            {[...Array(5)].map((_, index) => (
                                <Animated.View
                                    key={index}
                                    className="w-2 rounded-full"
                                    style={{
                                        backgroundColor: colors.green,
                                        height: audioLevelAnimation.interpolate({
                                            inputRange: [0, 1],
                                            outputRange: [8, 32],
                                        }),
                                        opacity: audioLevelAnimation.interpolate({
                                            inputRange: [0, 1],
                                            outputRange: [0.3, 1],
                                        }),
                                    }}
                                />
                            ))}
                        </View>
                    </View>
                )} */}
            </View>
            
            {/* ë…¹ìŒ ìƒíƒœ í…ìŠ¤íŠ¸ */}
            {/* <Text className={`text-sm font-medium mt-2 ${
                isRecording ? 'text-red-700' : 'text-blue-700'
            }`}>
                {isRecording ? `ë…¹ìŒ ì¤‘ ${formatTime(recordingDuration)}` : 'ë‹µë³€ ë…¹ìŒ'}
            </Text> */}

            {/* ìµœëŒ€ ì‹œê°„ í‘œì‹œ */}
            {/* {isRecording && (
                <Text className="text-xs text-gray-500 mt-1">
                    ìµœëŒ€ {formatTime(maxDuration)}
                </Text>
            )} */}
        </View>
    );
}
