import { useState, useRef, useEffect, useCallback } from 'react';
import { useNavigation } from '@react-navigation/native';
import { useUser } from '../contexts/UserContext';
import { Audio } from 'expo-av';
import { Animated } from 'react-native';
import { MicrophoneTestService, MicrophoneTestParams, STTTestResult } from '../services/microphoneTestService';
import { MicrophoneTestUtils } from '../utils/microphoneTestUtils';

export interface UseMicrophoneTestReturn {
    // ìƒíƒœ
    isMicTested: boolean;
    isRecording: boolean;
    isLoading: boolean;
    audioLevel: number;
    speechBubbleText: string;
    sttResult: STTTestResult | null;
    userId: string;
    
    // ì• ë‹ˆë©”ì´ì…˜
    audioLevelAnimation: Animated.Value;
    
    // í•¨ìˆ˜
    handleStart: () => Promise<void>;
    startMicTest: () => Promise<void>;
    canStart: boolean;
}

export const useMicrophoneTest = (routeParams: any): UseMicrophoneTestReturn => {
    const navigation = useNavigation();
    const { user } = useUser();
    
    // íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    const params = MicrophoneTestUtils.extractParams(routeParams) as MicrophoneTestParams;
    const userId = user?.userId || "1";
    
    // ë””ë²„ê¹…: ì‚¬ìš©ì ì •ë³´ì™€ í† í° ìƒíƒœ í™•ì¸
    console.log('ğŸ” useMicrophoneTest - ì‚¬ìš©ì ì •ë³´:', user);
    console.log('ğŸ” useMicrophoneTest - userId:', userId);
    console.log('ğŸ” useMicrophoneTest - user.token:', user?.token ? 'í† í° ìˆìŒ' : 'í† í° ì—†ìŒ');
    
    // ìƒíƒœ
    const [isMicTested, setIsMicTested] = useState(false);
    const [isRecording, setIsRecording] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [audioLevel, setAudioLevel] = useState(0);
    const [speechBubbleText, setSpeechBubbleText] = useState("ë§ˆì´í¬ë¥¼ í…ŒìŠ¤íŠ¸í• ê²Œìš”.\në§ˆì´í¬ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.");
    const [sttResult, setSttResult] = useState<STTTestResult | null>(null);
    
    // refs
    const recordingRef = useRef<Audio.Recording | null>(null);
    const audioLevelAnimation = useRef(new Animated.Value(0)).current;
    const intervalRef = useRef<ReturnType<typeof setInterval> | null>(null);

    // ëŒ€í™” ì‹œì‘ í•¸ë“¤ëŸ¬
    const handleStart = useCallback(async () => {
        try {
            const result = await MicrophoneTestService.startConversation(
                userId, 
                params.questionId
            );

            // Conversation í™”ë©´ìœ¼ë¡œ ì´ë™
            (navigation as any).navigate('Conversation', {
                questionText: params.questionText,
                questionId: params.questionId,
                conversationId: result.conversationId,
                cameraSessionId: result.cameraSessionId,
                microphoneSessionId: result.microphoneSessionId,
                userId: userId
            });
        } catch (error) {
            console.error('ëŒ€í™” ì„¸ì…˜ ì‹œì‘ ì‹¤íŒ¨:', error);
            MicrophoneTestUtils.showErrorAlert('ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        }
    }, [navigation, userId, params.questionText, params.questionId]);

    // ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹œì‘
    const startMicTest = useCallback(async () => {
        try {
            setIsLoading(true);
            setSpeechBubbleText("ë§ˆì´í¬ë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\nì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.");
            
            // STT í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë…¹ìŒ ì‹œì‘ ì½œë°± ì „ë‹¬)
            const result = await MicrophoneTestService.runSTTTest(() => {
                // ë…¹ìŒì´ ì‹¤ì œë¡œ ì‹œì‘ëœ í›„ì—ë§Œ ìƒíƒœ ì—…ë°ì´íŠ¸
                setIsLoading(false);
                setIsRecording(true);
                setSpeechBubbleText("3ì´ˆ ë™ì•ˆ ì•„ë¬´ ë§ì´ë‚˜ í•´ì£¼ì„¸ìš”...");
            });
            
            setSttResult(result);
            
            setIsRecording(false);
            setAudioLevel(0);
            audioLevelAnimation.setValue(0);
            
            if (result.success) {
                // STT ì„±ê³µ
                setSpeechBubbleText(`"${result.text}"ë¼ê³  ë§ì”€í•˜ì…¨ë„¤ìš”! ë§ˆì´í¬ê°€ ì˜ ë˜ê³  ìˆìŠµë‹ˆë‹¤.`);
                await MicrophoneTestService.updateMicrophoneSession(params.microphoneSessionId);
                setIsMicTested(true);
            } else {
                // STT ì‹¤íŒ¨
                setSpeechBubbleText(`ë‹¤ì‹œ í•œ ë²ˆ ë§ í•´ì£¼ì‹œê² ì–´ìš”?`);
                setIsMicTested(false);
            }

        } catch (error) {
            console.error('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹¤íŒ¨:', error);
            setIsLoading(false);
            setIsRecording(false);
            setSpeechBubbleText("í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        }
    }, [params.microphoneSessionId, audioLevelAnimation]);

    // ì´ˆê¸° ì„¤ì •
    useEffect(() => {
        return () => {
            if (recordingRef.current) {
                try {
                    MicrophoneTestService.stopRecording(recordingRef.current);
                } catch (error) {
                    console.log('Recording already unloaded');
                }
            }
            if (intervalRef.current) {
                clearInterval(intervalRef.current);
            }
        };
    }, []);

    // ì‹œì‘ ê°€ëŠ¥ ì—¬ë¶€
    const canStart = isMicTested;

    return {
        // ìƒíƒœ
        isMicTested,
        isRecording,
        isLoading,
        audioLevel,
        speechBubbleText,
        sttResult,
        userId,
        
        // ì• ë‹ˆë©”ì´ì…˜
        audioLevelAnimation,
        
        // í•¨ìˆ˜
        handleStart,
        startMicTest,
        canStart,
    };
};
